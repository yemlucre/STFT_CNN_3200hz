# 过拟合分析报告

## 模型信息
- **模型**: MobileNetV2
- **参数量**: 2,228,420
- **训练数据**: 6,821 样本
- **测试数据**: 1,882 样本
- **训练轮数**: 30 epochs

## 训练过程观察

### 关键指标对比

| Epoch | 训练Loss | 训练Acc | 测试Loss | 测试Acc | 过拟合程度 |
|-------|----------|---------|----------|---------|-----------|
| 1     | 0.4975   | 0.8031  | 0.6494   | 0.8656  | 低 ✓      |
| 5     | 0.0336   | 0.9918  | 1.0909   | 0.7906  | **严重** ⚠️ |
| 10    | 0.0095   | 0.9981  | 0.3911   | 0.8889  | 中等      |
| 14    | 0.0029   | 0.9996  | 0.7613   | 0.8820  | **严重** ⚠️ |
| 17    | 0.0023   | 0.9994  | 0.3265   | 0.9288  | 中等      |
| 28    | 0.0036   | 0.9997  | 0.2158   | 0.9591  | 中等 ✓    |
| 30    | 0.0296   | 0.9943  | 0.3032   | 0.8735  | 低        |

### 最佳结果
- **最佳测试准确率**: 95.91% (Epoch 28)
- **对应训练准确率**: 99.97%
- **准确率差距**: 4.06%

## 过拟合现象分析

### 1. 明显的过拟合迹象 🔴

#### （1）训练-测试准确率差距大
- 从 Epoch 5 开始，训练准确率已达到 **99.18%**，而测试准确率仅为 **79.06%**
- Epoch 14 训练准确率高达 **99.96%**，但测试准确率反而下降到 **88.20%**
- 存在高达 **11-20%** 的准确率差距，说明模型在训练集上记忆过度

#### （2）测试Loss波动剧烈
- Epoch 1-5: 测试Loss从 0.6494 急剧上升到 **1.0909**
- Epoch 14: 测试Loss上升到 **0.7613**，远高于训练Loss (0.0029)
- 测试Loss的波动范围：0.1534 ~ 1.0909，极不稳定

#### （3）训练Loss极低但泛化差
- 多个epoch训练Loss < 0.01（Epoch 10/13/14/17/22/25/28）
- 训练准确率频繁达到 99.9%+ 甚至 99.97%
- 但测试准确率在 78% - 96% 之间大幅波动

### 2. 过拟合的根本原因

#### （1）模型容量过大
- **MobileNetV2** 拥有 **222万参数**
- 训练样本仅 **6,821个**
- **参数/样本比** ≈ 326:1（每个样本对应300+参数）
- 模型容量远超数据集复杂度，容易记忆训练数据的噪声

#### （2）数据量相对不足
- 轴承故障诊断共 4 类
- 每类平均仅 ~1,700 训练样本
- STFT特征尺寸为 32×63 = 2,016 维
- 对于深度神经网络（特别是MobileNetV2），数据量偏少

#### （3）缺乏正则化手段
当前训练配置未使用：
- Dropout
- 数据增强（时间/频率域扰动）
- L2正则化（权重衰减）
- 早停（Early Stopping）

### 3. 后期训练的改善趋势

值得注意的是，**Epoch 16-28** 期间出现了一定的恢复：
- Epoch 16: 测试准确率回升到 **91.55%**
- Epoch 17: 进一步提升到 **92.88%**
- Epoch 22-25: 逐步提升到 **93.25% → 93.62% → 93.78%**
- **Epoch 28**: 达到最佳 **95.91%**

这可能是因为：
- 优化器在损失平原区域探索，找到更好的泛化解
- 训练数据的shuffle带来新的梯度方向
- 模型逐渐学到更鲁棒的特征表示

但 Epoch 29-30 又出现下降（86.45% → 87.35%），说明不稳定性依然存在。

## 改进建议

### 优先级 ⭐⭐⭐（强烈推荐）

1. **添加 Dropout 层**
   ```python
   # 在 MobileNetV2 的分类头前添加
   nn.Dropout(p=0.3)
   ```

2. **启用权重衰减**
   ```python
   optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)
   ```

3. **实现早停机制**
   ```python
   # 当测试loss连续5个epoch不下降时停止
   patience = 5
   ```

### 优先级 ⭐⭐（推荐）

4. **降低学习率或使用学习率调度**
   ```python
   scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=3)
   ```

5. **数据增强**
   - 时域：添加高斯噪声、随机缩放
   - 频域：频率掩码（SpecAugment）
   - STFT参数扰动

6. **尝试更小的模型**
   - **BaselineCNN** (仅19,268参数) 可能更适合当前数据量
   - 或者 **ResNet18** 精简版

### 优先级 ⭐（可选）

7. **增加训练数据**
   - 收集更多故障样本
   - 使用不同工况下的数据

8. **集成学习**
   - 训练多个模型并投票
   - 减少单模型过拟合的影响

## 对比：BaselineCNN 是否更好？

基于参数量对比：

| 模型 | 参数量 | 训练样本 | 参数/样本比 | 预期过拟合风险 |
|------|--------|----------|-------------|----------------|
| MobileNetV2 | 2,228,420 | 6,821 | 326:1 | **极高** 🔴 |
| ResNet18 | 11,172,292 | 6,821 | 1,638:1 | **极高** 🔴 |
| **BaselineCNN** | **19,268** | **6,821** | **2.8:1** | **低** ✅ |

**建议**：在当前数据规模下，**BaselineCNN** 更合适，预期可获得更好的测试准确率和稳定性。

## 结论

1. **MobileNetV2 存在明显的过拟合问题**，训练准确率接近100%，但测试准确率波动在78%-96%之间
2. **根本原因** 是模型参数量（222万）远超数据集规模（6,821样本），且缺乏正则化
3. **最佳测试准确率 95.91%** 出现在 Epoch 28，但不稳定
4. **强烈建议** 添加 Dropout、权重衰减、早停机制
5. **考虑使用 BaselineCNN** 进行对比实验，可能获得更稳定的泛化性能

---

*生成时间: 2026-01-10*  
*基于训练日志: MobileNetV2, 30 epochs*
